# 機械学習勉強会2025実施計画

## 目的

機械学習の基礎から応用までを体系的に学び、Rustを用いたfrom scratch実装及びPytourch, scikit-learn等のライブラリを活用した実践的なスキルを習得することを目的とする。
アルゴリズムのみではなく、その数学的背景や研究史も重要視し最終的に参加者が自律的に論文などを通した学習ができるようになることを目指す。

## 形式

TypstのTouyingで作成したスライドを用いて部室及びDiscord上で1時間前後の講義を行う。
Rustコードは私が作成したコードをGitHubで公開し、参加者は各自クローンして実行しながら学習を進める。
PythonコードはJupyter Notebook形式で提供し、参加者は各自実行しながら学習を進める。

## 第１回：AIの世界へようこそ - 基礎と実践の第一歩

1. **イントロダクション**：本勉強会の目的とゴール
1. **アジェンダ**：本日の学習内容
1. **【概論】人工知能とは？**：定義と目指すもの
1. **AIの歴史①**：第1次AIブーム（探索と推論の時代）
1. **AIの歴史②**：冬の時代と教訓
1. **AIの歴史③**：第2次AIブーム（知識ベースのアプローチ）
1. **AIの歴史④**：機械学習の台頭
1. **AIの歴史⑤**：深層学習の衝撃と現代
1. **【機械学習の全体像】**：3つの主要なアプローチ
1. **教師あり学習**：正解データから学ぶ
1. **教師なし学習**：データ内在の構造を発見する
1. **強化学習**：試行錯誤を通じて最適な行動を学習する
1. **【教師あり学習の基本】**：分類タスクと回帰タスク
1. **分類タスクの例**：画像認識、スパムメールフィルタ
1. **回帰タスクの例**：株価予測、不動産価格予測
1. **【実践】**：Google Teachable Machineで画像分類モデルを体験
1. **【開発環境構築】**：RustとPythonのセットアップ
1. **Rust環境の構築手順**
1. **Python (Jupyter Notebook) 環境の構築手順**
1. **まとめと次回予告**

## 第２回：予測モデルの原点 - 線形回帰とロジスティック回帰

1. **前回の振り返り**：AIの歴史と機械学習の3分類
1. **アジェンダ**：本日の学習内容
1. **【回帰問題の基礎】線形回帰**：シンプルな予測モデル
1. **モデルの表現**：y = wx + b
1. **数学的背景**：最小二乗法
1. **損失関数とは？**：モデルの性能を測る指標
1. **MSE（平均二乗誤差）**：回帰問題で最も基本的な損失関数
1. **MSEを最小化する**: 線形回帰の場合MSEはただの二次関数になり解析的に解ける  
1. **【実装①】**：Rustによる線形回帰のfrom scratch実装
1. **コード解説**：データ構造、学習ループ、パラメータ更新
1. **学習結果の可視化**：予測直線を描画する
1. **応用**：重回帰と多項式近似による表現力向上
1. **【分類問題への応用】ロジスティック回帰**
1. **シグモイド関数**：出力を0から1の確率に変換
1. **損失関数**：クロスエントロピー誤差
1. **【実装②】**：Rustによるロジスティック回帰のfrom scratch実装
1. **モデルの評価**：k分割交差検証による過学習の抑制
1. **【ライブラリ活用】**：scikit-learnによる線形回帰
1. **【ライブラリ活用】**：scikit-learnによるロジスティック回帰
1. **まとめと次回予告**

## 第３回：最適化問題の探求 - 線形計画法と二次計画法

1. **前回の振り返り**：線形回帰とロジスティック回帰
1. **アジェンダ**：本日の学習内容
1. **【最適化問題とは】**：制約の中で最良の解を見つける
1. **機械学習における最適化**：損失関数の最小化
1. **線形計画法（LP）の紹介**
1. **LPの構成要素**：目的関数、決定変数、制約条件
1. **具体例①**：生産計画問題
1. **具体例②**：輸送問題
1. **図的解法**：2次元問題の可視化
1. **シンプレックス法**：LPの一般的な解法（概念）
1. **双対問題**：問題の別の側面
1. **【応用】二次計画法（QP）**
1. **QPの構成要素**：二次形式の目的関数
1. **LPとQPの違い**
1. **機械学習におけるQPの応用**：サポートベクターマシン（SVM）への導入
1. **ラグランジュの未定乗数法**：制約付き最適化の基礎
1. **KKT条件**：最適解が満たすべき条件
1. **【実践】**：Pythonライブラリを用いたLP問題の求解
1. **【実践】**：Pythonライブラリを用いたQP問題の求解
1. **まとめと次回予告**：SVMへの繋がり

## 第４回：マージン最大化による分類 - サポートベクターマシン(SVM)

1. **前回の振り返り**：線形計画法と二次計画法
1. **アジェンダ**：本日の学習内容
1. **【SVMの直感的理解】**：最もうまく分けられる境界線を探す
1. **マージンとは？**：境界線とデータ点との距離
1. **マージン最大化**：なぜマージンを最大化するのか？
1. **サポートベクター**：マージンを決定する重要なデータ点
1. **【SVMの定式化】**：ハードマージンSVM
1. **制約付き最適化問題として**：二次計画問題への帰着
1. **ラグランジュの未定乗数法**と双対問題
1. **ソフトマージンSVM**：ノイズや外れ値への対応
1. **スラック変数**：マージン侵害を許容する
1. **ハイパーパラメータC**：誤分類へのペナルティ
1. **【非線形分類への拡張】カーネルトリック**
1. **カーネル法**：高次元空間への写像
1. **代表的なカーネル関数**：多項式カーネル、RBFカーネル
1. **【実装①】**：RustによるSVMのfrom scratch実装
1. **コード解説**：QPソルバーの利用とカーネル計算
1. **学習結果の可視化**：決定境界とマージン
1. **【ライブラリ活用】**：scikit-learnによるSVMの実装とチューニング
1. **まとめと次回予告**

## 第５回：意思決定のモデル化 - 決定木とアンサンブル学習

1. **前回の振り返り**：サポートベクターマシン
1. **アジェンダ**：本日の学習内容
1. **【決定木の基礎】**：Yes/Noの質問でデータを分割
1. **決定木の構造**：根ノード、内部ノード、葉ノード
1. **不純度とは？**：分割の"良さ"を測る指標
1. **情報利得**：どれだけ不純度が減少したか
1. **ジニ不純度**：もう一つの不純度指標
1. **決定木の学習アルゴリズム**：再帰的な分割
1. **過学習と剪定**：モデルの複雑さを制御する
1. **【実装①】**：Rustによる決定木のfrom scratch実装
1. **コード解説**：再帰構造と不純度計算
1. **【アンサンブル学習】**："三人寄れば文殊の知恵"
1. **バギング**：異なるデータで学習したモデルを多数決（例：ランダムフォレスト）
1. **ブースティング**：モデルの"間違い"に注目して逐次的に改善（例：勾配ブースティング）
1. **スタッキング**：モデルの予測を新たな入力として学習
1. **ランダムフォレスト**：決定木 + バギング
1. **勾配ブースティング**：決定木 + ブースティング
1. **【ライブラリ活用】**：scikit-learnによる決定木の実装
1. **【ライブラリ活用】**：scikit-learnによるランダムフォレストと勾配ブースティング
1. **まとめと次回予告**

## 第６回：脳を模倣する - ニューラルネットワークの基礎

1. **前回の振り返り**：決定木とアンサンブル学習
1. **アジェンダ**：本日の学習内容
1. **【ニューラルネットワークの着想】**：生物の神経細胞
1. **パーセプトロン**：最も単純なニューラルネットワーク
1. **活性化関数**：ステップ関数からシグモイド関数へ
1. **多層パーセプトロン（MLP）**：層を重ねて表現力を高める
1. **活性化関数の役割**：非線形性の導入
1. **代表的な活性化関数**：シグモイド、tanh、ReLU
1. **【学習の仕組み】誤差逆伝播法（バックプロパゲーション）**
1. **順伝播**：入力から出力を計算
1. **逆伝播**：出力の誤差を逆方向に伝播させ、重みを更新
1. **計算グラフ**：誤差逆伝播法の視覚的理解
1. **勾配消失問題**：シグモイド関数の課題
1. **【実装①】**：Rustによる単純なMLPのfrom scratch実装
1. **コード解説**：順伝播と誤差逆伝播
1. **学習結果の可視化**：非線形な決定境界
1. **【ライブラリ活用】**：PyTorchによるMLPの実装
1. **PyTorchの基本**：Tensor、Autograd、Module
1. **余談**：シグモイド関数とボルツマンマシンの関係
1. **まとめと次回予告**

## 第７回：深層学習のテクニック - より深く、より賢く

1. **前回の振り返り**：ニューラルネットワークと誤差逆伝播法
1. **アジェンダ**：本日の学習内容
1. **【深層化の課題】**：なぜ単純に層を重ねるだけではダメなのか？
1. **勾配消失・爆発問題**
1. **対策①：活性化関数の工夫**
1. **ReLU（Rectified Linear Unit）**とその派生（Leaky ReLU, ELU）
1. **対策②：重みの初期化**
1. **He初期化**、Xavier初期化
1. **対策③：バッチ正規化**
1. **内部共変量シフト問題**とバッチ正規化の役割
1. **【過学習への対策】**
1. **ドロップアウト**：ニューロンをランダムに無効化
1. **【最適化手法の進化】**
1. **SGD（確率的勾配降下法）**の課題
1. **Momentum**：慣性を加える
1. **Adam**：適応的な学習率調整
1. **【実装①】**：Rustで深層ニューラルネットワークを実装（各種テクニックを導入）
1. **コード解説**：バッチ正規化、ドロップアウトの実装
1. **【ライブラリ活用】**：PyTorchで各種テクニックを適用
1. **まとめと次回予告**

## 第８回：自動微分の魔法 - PyTorchの心臓部を探る

1. **前回の振り返り**：深層学習のテクニック
1. **アジェンダ**：本日の学習内容
1. **【自動微分とは】**：誤差逆伝播法を自動化する技術
1. **手動微分 vs 数値微分 vs 自動微分**
1. **計算グラフ**：自動微分のためのデータ構造
1. **ノード**：変数や演算
1. **エッジ**：データの流れ
1. **【自動微分の仕組み】**：2つのモード
1. **フォワードモード（接線モード）**
1. **フォワードモードの動作原理**
1. **リバースモード（随伴モード）**
1. **リバースモードの動作原理**
1. **フォワード vs リバース**：どちらをいつ使うか？
1. **深層学習におけるリバースモードの優位性**
1. **【実装①】**：Rustによる自動微分ライブラリのfrom scratch実装
1. **コード解説**：計算グラフの構築
1. **コード解説**：フォワードモードの実装
1. **コード解説**：リバースモードの実装
1. **実装したライブラリで簡単なモデルを学習**
1. **まとめと次回予告**

## 第９回：画像認識の王様 - 畳み込みニューラルネットワーク(CNN)

1. **前回の振り返り**：自動微分の仕組み
1. **アジェンダ**：本日の学習内容
1. **【CNN登場の背景】**：なぜMLPでは画像認識が難しいのか？
1. **画像の局所性**とパラメータ数の爆発
1. **【CNNのコアアイデア】**
1. **畳み込み層**：特徴を抽出するフィルター
1. **カーネル（フィルター）**、ストライド、パディング
1. **プーリング層**：情報を圧縮し、位置不変性を獲得
1. **マックスプーリング**とアベレージプーリング
1. **CNNの全体構造**：畳み込み層＋プーリング層＋全結合層
1. **【代表的なCNNアーキテクチャ】**
1. **LeNet**：CNNの元祖
1. **AlexNet**：深層学習ブームの火付け役
1. **VGG**：層を深くすることの有効性を示す
1. **ResNet**：スキップ接続による超深層化の実現
1. **【実装①】**：RustによるCNNのfrom scratch実装
1. **コード解説**：畳み込み層とプーリング層の実装
1. **CIFAR-10データセットでの学習**
1. **【ライブラリ活用】**：PyTorchによるCNNの実装と学習済みモデルの利用
1. **まとめと次回予告**

## 第１０回：時系列データを扱う - 再帰型ニューラルネットワーク(RNN)

1. **前回の振り返り**：畳み込みニューラルネットワーク(CNN)
1. **アジェンダ**：本日の学習内容
1. **【RNNの必要性】**：なぜCNN/MLPでは時系列データが扱えないのか？
1. **シーケンスデータ**：文章、音声、株価など
1. **【RNNの基本構造】**：過去の情報を記憶するループ構造
1. **隠れ状態**：過去の文脈を保持するベクトル
1. **BPTT（Backpropagation Through Time）**：RNNの学習方法
1. **【RNNの課題】長期依存性の問題**
1. **勾配消失・爆発問題**がRNNでより深刻になる理由
1. **【課題の克服】進化したRNN**
1. **LSTM（Long Short-Term Memory）**：ゲート機構による情報の取捨選択
1. **入力ゲート、忘却ゲート、出力ゲート**
1. **GRU（Gated Recurrent Unit）**：LSTMの簡略版
1. **【実装①】**：RustによるRNN/LSTMのfrom scratch実装
1. **コード解説**：BPTTとゲート機構の実装
1. **【ライブラリ活用】**：PyTorchによるRNN/LSTMの実装
1. **【自然言語処理への応用】**
1. **トークン化**：文章を単語や文字に分割
1. **単語埋め込み（Word Embedding）**：単語をベクトルで表現
1. **まとめと次回予告**

## 第１１回：試行錯誤の科学 - 強化学習の基礎

1. **前回の振り返り**：再帰型ニューラルネットワーク(RNN)
1. **アジェンダ**：本日の学習内容
1. **【強化学習とは】**：教師あり/なし学習との違い
1. **強化学習の構成要素**：エージェント、環境、状態、行動、報酬
1. **【問題の定式化】マルコフ決定過程（MDP）**
1. **状態遷移確率**と**報酬関数**
1. **方策（Policy）**：エージェントの行動指針
1. **価値関数**：状態や行動の"良さ"を測る
1. **状態価値関数 V(s)** と **行動価値関数 Q(s, a)**
1. **Bellman方程式**：価値関数の再帰的な関係式
1. **【古典的な解法】**
1. **動的計画法**：環境のモデルが既知の場合
1. **モンテカルロ法**：エピソード終了まで待って学習
1. **TD（Temporal Difference）学習**：1ステップごとに学習
1. **【代表的なTD学習アルゴリズム】**
1. **SARSA**：方策オン型学習
1. **Q学習**：方策オフ型学習
1. **ε-greedy法**：探索と活用のトレードオフ
1. **【実装】**：Rustで簡単な迷路問題を解くQ学習を実装
1. **まとめと次回予告**

## 第１２回：深層学習との融合 - 深層強化学習

1. **前回の振り返り**：強化学習の基礎とQ学習
1. **アジェンダ**：本日の学習内容
1. **【深層強化学習の必要性】**：なぜQテーブルではダメなのか？
1. **状態空間の爆発**：現実世界の問題への対応
1. **【価値ベースの手法】DQN (Deep Q-Network)**
1. **Q関数をニューラルネットワークで近似**
1. **DQNの工夫①**：Experience Replay
1. **DQNの工夫②**：Target Network
1. **【方策ベースの手法】**
1. **方策勾配法**：方策を直接パラメータ化して最適化
1. **REINFORCEアルゴリズム**
1. **【Actor-Critic法】**
1. **価値ベースと方策ベースの融合**
1. **Actor**：方策を学習
1. **Critic**：価値関数を学習
1. **A2C, A3C**：Advantage Actor-Critic
1. **【実践】**：OpenAI Gymの紹介
1. **CartPole問題**：倒立振子の制御
1. **PyTorchを用いたDQNの実装**
1. **まとめと次回予告**

## 第１３回：データを生み出す - 生成モデル入門

1. **前回の振り返り**：深層強化学習
1. **アジェンダ**：本日の学習内容
1. **【生成モデルとは】**：データ分布を学習し、新たなデータを生成
1. **識別モデル vs 生成モデル**
1. **【エネルギーベースモデル】**
1. **ボルツマンマシン**と**制限付きボルツマンマシン（RBM）**
1. **【変分オートエンコーダ（VAE）】**
1. **オートエンコーダ**：次元削減と特徴抽出
1. **VAEの構造**：エンコーダとデコーダ
1. **潜在空間**と**再パラメータ化トリック**
1. **損失関数**：再構成誤差 + KLダイバージェンス
1. **【生成的敵対ネットワーク（GAN）】**
1. **Generator vs Discriminator**：偽札作りと警察の競争
1. **GANの学習プロセス**
1. **モード崩壊**などの課題
1. **【実装】**：PyTorchによるVAEの実装
1. **【実装】**：PyTorchによるGANの実装
1. **生成された画像の確認**
1. **応用例**：画像生成、データ拡張、異常検知
1. **まとめと次回予告**

## 第１４回：計算を加速する - GPUと並列計算

1. **前回の振り返り**：生成モデル（VAE, GAN）
1. **アジェンダ**：本日の学習内容
1. **【なぜGPUが必要か】**：CPUとGPUのアーキテクチャの違い
1. **CPU**：少数の高性能コア
1. **GPU**：多数の単純なコア
1. **並列計算の概念**：SIMD/SIMT
1. **【GPUプログラミングの基礎】CUDA**
1. **CUDAとは**：NVIDIA製GPU向けの並列計算プラットフォーム
1. **カーネル関数**：GPUで実行されるコード
1. **スレッド、ブロック、グリッド**の階層構造
1. **簡単なベクトル加算をCUDAで実装（概念）**
1. **【PyTorchでのGPU活用】**
1. **`.to('cuda')`**：TensorやモデルをGPUに転送
1. **CPUとGPU間のデータ転送の注意点**
1. **複数GPUでの学習**：`DataParallel` と `DistributedDataParallel`
1. **【実践】**：実際のモデル訓練におけるGPUの効果測定
1. **CPU vs GPU**：学習時間の比較
1. **【RustでのGPUプログラミング】**
1. **`cust`** や **`wgpu`** などのライブラリ紹介
1. **まとめと次回予告**

## 第１５回：自然言語処理の革命 - TransformerとAttention

1. **前回の振り返り**：GPUと並列計算
1. **アジェンダ**：本日の学習内容
1. **【RNNの限界】**：長期依存と並列化の困難さ
1. **【Attentionメカニズム】**：文中の重要な部分に"注目"する
1. **Attentionの仕組み**：Query, Key, Value
1. **自己注意（Self-Attention）**：文中の単語間の関係性を捉える
1. **【Transformerアーキテクチャ】**："Attention Is All You Need"
1. **RNNを完全に排除**
1. **エンコーダ・デコーダ構造**
1. **Multi-Head Attention**：複数の"視点"から注目
1. **Positional Encoding**：単語の位置情報を加える
1. **Feed-Forward Network**と**残差接続**
1. **【代表的なTransformerベースモデル】**
1. **BERT**：文脈を双方向から理解する
1. **GPT**：大規模な自己回帰言語モデル
1. **【実装】**：PyTorchによるTransformerの実装
1. **コード解説**：Self-AttentionとPositional Encoding
1. **【応用例】**
1. **機械翻訳、文章要約、質疑応答**
1. **二乗計算量の課題と軽量化手法**
1. **まとめと次回予告**

## 第１６回：チャットAIの舞台裏 - 大規模言語モデルの訓練

1. **前回の振り返り**：TransformerとAttention
1. **アジェンダ**：本日の学習内容
1. **【Nanochatを例に】**：ローカルで学習できるチャットAI
1. **大規模言語モデル（LLM）の仕組み**
1. **【ステップ１】事前学習（Pre-training）**
1. **目的**：一般的な言語能力の獲得
1. **膨大なテキストデータ**（Web、書籍など）
1. **自己教師あり学習**：次の単語予測、マスクされた単語の予測
1. **計算コスト**：膨大なGPUリソースが必要
1. **【ステップ２】ファインチューニング（Fine-tuning）**
1. **目的**：特定のタスクや対話スタイルへの適応
1. **指示チューニング（Instruction Tuning）**
1. **高品質な「指示-応答」ペアのデータセット**
1. **【ステップ３】強化学習による微調整（RLHF）**
1. **目的**：人間の好みに合うように出力を調整
1. **①報酬モデルの学習**：人間の評価データを基に、良い応答を予測するモデルを作成
1. **②強化学習**：報酬モデルを報酬関数として、LLMの方策を更新
1. **PPO（Proximal Policy Optimization）**アルゴリズム
1. **RLHFの重要性**：安全性、有用性、無害性の向上
1. **まとめと次回予告**

## 第１７回：画像生成の新時代 - Diffusionモデル

1. **前回の振り返り**：大規模言語モデルの訓練プロセス
1. **アジェンダ**：本日の学習内容
1. **【Diffusionモデルのアイデア】**：ノイズから画像を復元する
1. **GANやVAEとの比較**
1. **【ステップ１】拡散過程（Forward Process）**
1. **画像に少しずつノイズを加えていく**
1. **最終的には完全なノイズ画像に**
1. **この過程は固定であり、学習は不要**
1. **【ステップ２】逆拡散過程（Reverse Process）**
1. **ノイズ画像から少しずつノイズを除去していく**
1. **各ステップで加えられたノイズを予測するモデル（U-Net）を学習**
1. **U-Netアーキテクチャ**：スキップ接続を持つエンコーダ・デコーダ
1. **【代表的なDiffusionモデル】**
1. **DDPM (Denoising Diffusion Probabilistic Models)**
1. **DALL-E 2, Imagen, Stable Diffusion**：テキストからの画像生成（Text-to-Image）
1. **CLIP**によるテキストと画像の関連付け
1. **【実装】**：PyTorchによるシンプルなDiffusionモデルの実装
1. **コード解説**：拡散過程とU-Netによるノイズ予測
1. **応用例**：画像生成、画像修復（インペインティング）、超解像
1. **まとめと次回予告**

## 第１８回：言葉と画像の融合 - Vision & Languageモデル

1. **前回の振り返り**：Diffusionモデル
1. **アジェンダ**：本日の学習内容
1. **【マルチモーダル学習とは】**：複数のモダリティ（テキスト、画像、音声など）を同時に扱う
1. **なぜV&Lモデルが必要か？**
1. **【V&Lモデルの基礎】CLIP (Contrastive Language-Image Pre-training)**
1. **目的**：画像とテキストを同じ特徴量空間にマッピング
1. **学習方法**：大量の「画像-テキスト」ペアを使用
1. **対照学習（Contrastive Learning）**：対応するペアの類似度を高く、非対応のペアの類似度を低くする
1. **ゼロショット画像分類**：学習時に存在しなかったクラスも分類可能
1. **【代表的なV&Lモデル】**
1. **DALL-E**：テキストから画像を生成（GPT-3 + VQ-VAE）
1. **VisualBERT, ViLBERT**：BERTをV&Lタスクに応用
1. **Flamingo, BLIP**：より高度なV&Lモデル
1. **【V&Lモデルの応用例】**
1. **画像キャプション生成**：画像の内容を説明する文章を生成
1. **VQA（Visual Question Answering）**：画像に関する質問に答える
1. **画像検索**：テキストクエリによる画像検索
1. **【実装】**：PyTorchとHugging Face Transformersを用いたCLIPの活用
1. **ゼロショット画像分類を試す**
1. **まとめと次回予告**

## 第１９回：確率分布の変換 - Flowベースモデルと強化学習への応用

1. **前回の振り返り**：Vision & Languageモデル
1. **アジェンダ**：本日の学習内容
1. **【Flowベースモデルとは】**：可逆な変換で複雑な確率分布を表現
1. **VAE, GANとの比較**：厳密な尤度計算が可能
1. **【正規化フロー（Normalizing Flows）】**
1. **基本アイデア**：単純な分布（例：ガウス分布）を複雑な変換で目標分布に変形
1. **可逆なニューラルネットワーク**
1. **ヤコビアン行列式**の計算
1. **代表的なアーキテクチャ**：NICE, RealNVP, Glow
1. **【強化学習への応用】**
1. **確率的方策**の表現力向上
1. **探索の効率化**
1. **π-O (Pi-O)**：Flowベースモデルを用いたオフポリシー強化学習
1. **【ロボット制御への道筋】**
1. **ロボットアームの制御問題**：連続的な行動空間
1. **模倣学習**：専門家のデモデータから学習
1. **強化学習**：試行錯誤によるスキルの獲得
1. **シミュレーション環境の重要性**
1. **Sim-to-Real**：シミュレーションから実機への転移
1. **まとめと次回予告**：最終回プロジェクト

## 第２０回：最終プロジェクト - 強化学習によるロボットアーム制御1

1. **前回の振り返り**：Flowベースモデルとロボット制御への展望
1. **アジェンダ**：本日の学習内容
1. **【プロジェクト目標】**：強化学習を用いてロボットアームを制御する
1. **タスク設定**：特定の位置にあるオブジェクトを掴む
1. **【ステップ１】シミュレーション環境の構築**
1. **PyBullet** や **MuJoCo** などの物理シミュレータ
1. **ロボットアームモデル**の読み込み
1. **状態空間の定義**：関節角度、ターゲット位置など
1. **行動空間の定義**：各関節へのトルクや目標角度
1. **報酬関数の設計**：目標達成へのインセンティブ
1. **【ステップ２】強化学習モデルの設計**
1. **アルゴリズムの選択**：SAC (Soft Actor-Critic) や PPO
1. **ニューラルネットワークの設計**：ActorとCriticのネットワーク構造
1. **ハイパーパラメータの調整**
1. **【ステップ３】モデルの訓練と評価**
1. **シミュレーション環境での学習実行**
1. **学習曲線のモニタリング**：報酬の推移を確認
1. **訓練済みモデルの評価**：タスク成功率を測定
1. **【ステップ４】実機への適用とデモンストレーション**
1. **Sim-to-Realの課題と対策**
1. **実機ロボットアームでの動作確認**

## 第２１回：最終プロジェクト - 強化学習によるロボットアーム制御2

1. **前回の振り返り**：強化学習によるロボットアーム制御の基礎
1. **アジェンダ**：本日の学習内容
1. **模倣学習の導入**：専門家デモからの初期学習
1. **デモデータの収集**：人間操作や既存の制御アルゴリズム
1. **Behavior Cloning**：教師あり学習による方策の初期化
1. **強化学習との組み合わせ**：模倣学習後の微調整
1. **探索戦略の改善**：ノイズ注入やε-greedy法の活用
1. **報酬関数の改良**：より細かいインセンティブ設計
1. **学習の安定化**：ターゲットネットワークやExperience Replayの活用
1. **実機でのテストとデバッグ**：シミュレーションと実機のギャップ調整
1. **最終評価**：タスク成功率と学習効率の比較
1. **まとめとコースの振り返り**：学んだ内容の総括と今後の展望
